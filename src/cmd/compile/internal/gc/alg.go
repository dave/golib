// Copyright 2016 The Go Authors. All rights reserved.
// Use of this source code is governed by a BSD-style
// license that can be found in the LICENSE file.

package gc

import (
	"fmt"
	"github.com/dave/golib/src/cmd/compile/internal/types"
)

// AlgKind describes the kind of algorithms used for comparing and
// hashing a Type.
type AlgKind int

const (
	// These values are known by runtime.
	ANOEQ AlgKind = iota
	AMEM0
	AMEM8
	AMEM16
	AMEM32
	AMEM64
	AMEM128
	ASTRING
	AINTER
	ANILINTER
	AFLOAT32
	AFLOAT64
	ACPLX64
	ACPLX128

	// Type can be compared/hashed as regular memory.
	AMEM AlgKind = 100

	// Type needs special comparison/hashing functions.
	ASPECIAL AlgKind = -1
)

// IsComparable reports whether t is a comparable type.
func (pstate *PackageState) IsComparable(t *types.Type) bool {
	a, _ := pstate.algtype1(t)
	return a != ANOEQ
}

// IsRegularMemory reports whether t can be compared/hashed as regular memory.
func (pstate *PackageState) IsRegularMemory(t *types.Type) bool {
	a, _ := pstate.algtype1(t)
	return a == AMEM
}

// IncomparableField returns an incomparable Field of struct Type t, if any.
func (pstate *PackageState) IncomparableField(t *types.Type) *types.Field {
	for _, f := range t.FieldSlice(pstate.types) {
		if !pstate.IsComparable(f.Type) {
			return f
		}
	}
	return nil
}

// algtype is like algtype1, except it returns the fixed-width AMEMxx variants
// instead of the general AMEM kind when possible.
func (pstate *PackageState) algtype(t *types.Type) AlgKind {
	a, _ := pstate.algtype1(t)
	if a == AMEM {
		switch t.Width {
		case 0:
			return AMEM0
		case 1:
			return AMEM8
		case 2:
			return AMEM16
		case 4:
			return AMEM32
		case 8:
			return AMEM64
		case 16:
			return AMEM128
		}
	}

	return a
}

// algtype1 returns the AlgKind used for comparing and hashing Type t.
// If it returns ANOEQ, it also returns the component type of t that
// makes it incomparable.
func (pstate *PackageState) algtype1(t *types.Type) (AlgKind, *types.Type) {
	if t.Broke() {
		return AMEM, nil
	}
	if t.Noalg() {
		return ANOEQ, t
	}

	switch t.Etype {
	case TANY, TFORW:
		// will be defined later.
		return ANOEQ, t

	case TINT8, TUINT8, TINT16, TUINT16,
		TINT32, TUINT32, TINT64, TUINT64,
		TINT, TUINT, TUINTPTR,
		TBOOL, TPTR32, TPTR64,
		TCHAN, TUNSAFEPTR:
		return AMEM, nil

	case TFUNC, TMAP:
		return ANOEQ, t

	case TFLOAT32:
		return AFLOAT32, nil

	case TFLOAT64:
		return AFLOAT64, nil

	case TCOMPLEX64:
		return ACPLX64, nil

	case TCOMPLEX128:
		return ACPLX128, nil

	case TSTRING:
		return ASTRING, nil

	case TINTER:
		if t.IsEmptyInterface(pstate.types) {
			return ANILINTER, nil
		}
		return AINTER, nil

	case TSLICE:
		return ANOEQ, t

	case TARRAY:
		a, bad := pstate.algtype1(t.Elem(pstate.types))
		switch a {
		case AMEM:
			return AMEM, nil
		case ANOEQ:
			return ANOEQ, bad
		}

		switch t.NumElem(pstate.types) {
		case 0:
			// We checked above that the element type is comparable.
			return AMEM, nil
		case 1:
			// Single-element array is same as its lone element.
			return a, nil
		}

		return ASPECIAL, nil

	case TSTRUCT:
		fields := t.FieldSlice(pstate.types)

		// One-field struct is same as that one field alone.
		if len(fields) == 1 && !fields[0].Sym.IsBlank() {
			return pstate.algtype1(fields[0].Type)
		}

		ret := AMEM
		for i, f := range fields {
			// All fields must be comparable.
			a, bad := pstate.algtype1(f.Type)
			if a == ANOEQ {
				return ANOEQ, bad
			}

			// Blank fields, padded fields, fields with non-memory
			// equality need special compare.
			if a != AMEM || f.Sym.IsBlank() || pstate.ispaddedfield(t, i) {
				ret = ASPECIAL
			}
		}

		return ret, nil
	}

	pstate.Fatalf("algtype1: unexpected type %v", t)
	return 0, nil
}

// Generate a helper function to compute the hash of a value of type t.
func (pstate *PackageState) genhash(sym *types.Sym, t *types.Type) {
	if pstate.Debug['r'] != 0 {
		fmt.Printf("genhash %v %v\n", sym, t)
	}

	pstate.lineno = pstate.autogeneratedPos // less confusing than end of input
	pstate.dclcontext = PEXTERN

	// func sym(p *T, h uintptr) uintptr
	tfn := pstate.nod(OTFUNC, nil, nil)
	tfn.List.Set2(
		pstate.namedfield("p", pstate.types.NewPtr(t)),
		pstate.namedfield("h", pstate.types.Types[TUINTPTR]),
	)
	tfn.Rlist.Set1(pstate.anonfield(pstate.types.Types[TUINTPTR]))

	fn := pstate.dclfunc(sym, tfn)
	np := asNode(tfn.Type.Params(pstate.types).Field(pstate.types, 0).Nname)
	nh := asNode(tfn.Type.Params(pstate.types).Field(pstate.types, 1).Nname)

	// genhash is only called for types that have equality but
	// cannot be handled by the standard algorithms,
	// so t must be either an array or a struct.
	switch t.Etype {
	default:
		pstate.Fatalf("genhash %v", t)

	case types.TARRAY:
		// An array of pure memory would be handled by the
		// standard algorithm, so the element type must not be
		// pure memory.
		hashel := pstate.hashfor(t.Elem(pstate.types))

		n := pstate.nod(ORANGE, nil, pstate.nod(OIND, np, nil))
		ni := pstate.newname(pstate.lookup("i"))
		ni.Type = pstate.types.Types[TINT]
		n.List.Set1(ni)
		n.SetColas(true)
		pstate.colasdefn(n.List.Slice(), n)
		ni = n.List.First()

		// h = hashel(&p[i], h)
		call := pstate.nod(OCALL, hashel, nil)

		nx := pstate.nod(OINDEX, np, ni)
		nx.SetBounded(true)
		na := pstate.nod(OADDR, nx, nil)
		call.List.Append(na)
		call.List.Append(nh)
		n.Nbody.Append(pstate.nod(OAS, nh, call))

		fn.Nbody.Append(n)

	case types.TSTRUCT:
		// Walk the struct using memhash for runs of AMEM
		// and calling specific hash functions for the others.
		for i, fields := 0, t.FieldSlice(pstate.types); i < len(fields); {
			f := fields[i]

			// Skip blank fields.
			if f.Sym.IsBlank() {
				i++
				continue
			}

			// Hash non-memory fields with appropriate hash function.
			if !pstate.IsRegularMemory(f.Type) {
				hashel := pstate.hashfor(f.Type)
				call := pstate.nod(OCALL, hashel, nil)
				nx := pstate.nodSym(OXDOT, np, f.Sym) // TODO: fields from other packages?
				na := pstate.nod(OADDR, nx, nil)
				call.List.Append(na)
				call.List.Append(nh)
				fn.Nbody.Append(pstate.nod(OAS, nh, call))
				i++
				continue
			}

			// Otherwise, hash a maximal length run of raw memory.
			size, next := pstate.memrun(t, i)

			// h = hashel(&p.first, size, h)
			hashel := pstate.hashmem(f.Type)
			call := pstate.nod(OCALL, hashel, nil)
			nx := pstate.nodSym(OXDOT, np, f.Sym) // TODO: fields from other packages?
			na := pstate.nod(OADDR, nx, nil)
			call.List.Append(na)
			call.List.Append(nh)
			call.List.Append(pstate.nodintconst(size))
			fn.Nbody.Append(pstate.nod(OAS, nh, call))

			i = next
		}
	}

	r := pstate.nod(ORETURN, nil, nil)
	r.List.Append(nh)
	fn.Nbody.Append(r)

	if pstate.Debug['r'] != 0 {
		dumplist("genhash body", fn.Nbody)
	}

	pstate.funcbody()

	fn.Func.SetDupok(true)
	fn = pstate.typecheck(fn, Etop)

	pstate.Curfn = fn
	pstate.typecheckslice(fn.Nbody.Slice(), Etop)
	pstate.Curfn = nil

	if pstate.debug_dclstack != 0 {
		pstate.testdclstack()
	}

	// Disable safemode while compiling this code: the code we
	// generate internally can refer to unsafe.Pointer.
	// In this case it can happen if we need to generate an ==
	// for a struct containing a reflect.Value, which itself has
	// an unexported field of type unsafe.Pointer.
	old_safemode := pstate.safemode
	pstate.safemode = false

	fn.Func.SetNilCheckDisabled(true)
	pstate.funccompile(fn)

	pstate.safemode = old_safemode
}

func (pstate *PackageState) hashfor(t *types.Type) *Node {
	var sym *types.Sym

	switch a, _ := pstate.algtype1(t); a {
	case AMEM:
		pstate.Fatalf("hashfor with AMEM type")
	case AINTER:
		sym = pstate.Runtimepkg.Lookup(pstate.types, "interhash")
	case ANILINTER:
		sym = pstate.Runtimepkg.Lookup(pstate.types, "nilinterhash")
	case ASTRING:
		sym = pstate.Runtimepkg.Lookup(pstate.types, "strhash")
	case AFLOAT32:
		sym = pstate.Runtimepkg.Lookup(pstate.types, "f32hash")
	case AFLOAT64:
		sym = pstate.Runtimepkg.Lookup(pstate.types, "f64hash")
	case ACPLX64:
		sym = pstate.Runtimepkg.Lookup(pstate.types, "c64hash")
	case ACPLX128:
		sym = pstate.Runtimepkg.Lookup(pstate.types, "c128hash")
	default:
		sym = pstate.typesymprefix(".hash", t)
	}

	n := pstate.newname(sym)
	n.SetClass(PFUNC)
	n.Type = pstate.functype(nil, []*Node{
		pstate.anonfield(pstate.types.NewPtr(t)),
		pstate.anonfield(pstate.types.Types[TUINTPTR]),
	}, []*Node{
		pstate.anonfield(pstate.types.Types[TUINTPTR]),
	})
	return n
}

// geneq generates a helper function to
// check equality of two values of type t.
func (pstate *PackageState) geneq(sym *types.Sym, t *types.Type) {
	if pstate.Debug['r'] != 0 {
		fmt.Printf("geneq %v %v\n", sym, t)
	}

	pstate.lineno = pstate.autogeneratedPos // less confusing than end of input
	pstate.dclcontext = PEXTERN

	// func sym(p, q *T) bool
	tfn := pstate.nod(OTFUNC, nil, nil)
	tfn.List.Set2(
		pstate.namedfield("p", pstate.types.NewPtr(t)),
		pstate.namedfield("q", pstate.types.NewPtr(t)),
	)
	tfn.Rlist.Set1(pstate.anonfield(pstate.types.Types[TBOOL]))

	fn := pstate.dclfunc(sym, tfn)
	np := asNode(tfn.Type.Params(pstate.types).Field(pstate.types, 0).Nname)
	nq := asNode(tfn.Type.Params(pstate.types).Field(pstate.types, 1).Nname)

	// geneq is only called for types that have equality but
	// cannot be handled by the standard algorithms,
	// so t must be either an array or a struct.
	switch t.Etype {
	default:
		pstate.Fatalf("geneq %v", t)

	case TARRAY:
		// An array of pure memory would be handled by the
		// standard memequal, so the element type must not be
		// pure memory. Even if we unrolled the range loop,
		// each iteration would be a function call, so don't bother
		// unrolling.
		nrange := pstate.nod(ORANGE, nil, pstate.nod(OIND, np, nil))

		ni := pstate.newname(pstate.lookup("i"))
		ni.Type = pstate.types.Types[TINT]
		nrange.List.Set1(ni)
		nrange.SetColas(true)
		pstate.colasdefn(nrange.List.Slice(), nrange)
		ni = nrange.List.First()

		// if p[i] != q[i] { return false }
		nx := pstate.nod(OINDEX, np, ni)

		nx.SetBounded(true)
		ny := pstate.nod(OINDEX, nq, ni)
		ny.SetBounded(true)

		nif := pstate.nod(OIF, nil, nil)
		nif.Left = pstate.nod(ONE, nx, ny)
		r := pstate.nod(ORETURN, nil, nil)
		r.List.Append(pstate.nodbool(false))
		nif.Nbody.Append(r)
		nrange.Nbody.Append(nif)
		fn.Nbody.Append(nrange)

		// return true
		ret := pstate.nod(ORETURN, nil, nil)
		ret.List.Append(pstate.nodbool(true))
		fn.Nbody.Append(ret)

	case TSTRUCT:
		var cond *Node
		and := func(n *Node) {
			if cond == nil {
				cond = n
				return
			}
			cond = pstate.nod(OANDAND, cond, n)
		}

		// Walk the struct using memequal for runs of AMEM
		// and calling specific equality tests for the others.
		for i, fields := 0, t.FieldSlice(pstate.types); i < len(fields); {
			f := fields[i]

			// Skip blank-named fields.
			if f.Sym.IsBlank() {
				i++
				continue
			}

			// Compare non-memory fields with field equality.
			if !pstate.IsRegularMemory(f.Type) {
				and(pstate.eqfield(np, nq, f.Sym))
				i++
				continue
			}

			// Find maximal length run of memory-only fields.
			size, next := pstate.memrun(t, i)

			// TODO(rsc): All the calls to newname are wrong for
			// cross-package unexported fields.
			if s := fields[i:next]; len(s) <= 2 {
				// Two or fewer fields: use plain field equality.
				for _, f := range s {
					and(pstate.eqfield(np, nq, f.Sym))
				}
			} else {
				// More than two fields: use memequal.
				and(pstate.eqmem(np, nq, f.Sym, size))
			}
			i = next
		}

		if cond == nil {
			cond = pstate.nodbool(true)
		}

		ret := pstate.nod(ORETURN, nil, nil)
		ret.List.Append(cond)
		fn.Nbody.Append(ret)
	}

	if pstate.Debug['r'] != 0 {
		dumplist("geneq body", fn.Nbody)
	}

	pstate.funcbody()

	fn.Func.SetDupok(true)
	fn = pstate.typecheck(fn, Etop)

	pstate.Curfn = fn
	pstate.typecheckslice(fn.Nbody.Slice(), Etop)
	pstate.Curfn = nil

	if pstate.debug_dclstack != 0 {
		pstate.testdclstack()
	}

	// Disable safemode while compiling this code: the code we
	// generate internally can refer to unsafe.Pointer.
	// In this case it can happen if we need to generate an ==
	// for a struct containing a reflect.Value, which itself has
	// an unexported field of type unsafe.Pointer.
	old_safemode := pstate.safemode
	pstate.safemode = false

	// Disable checknils while compiling this code.
	// We are comparing a struct or an array,
	// neither of which can be nil, and our comparisons
	// are shallow.
	fn.Func.SetNilCheckDisabled(true)
	pstate.funccompile(fn)

	pstate.safemode = old_safemode
}

// eqfield returns the node
// 	p.field == q.field
func (pstate *PackageState) eqfield(p *Node, q *Node, field *types.Sym) *Node {
	nx := pstate.nodSym(OXDOT, p, field)
	ny := pstate.nodSym(OXDOT, q, field)
	ne := pstate.nod(OEQ, nx, ny)
	return ne
}

// eqmem returns the node
// 	memequal(&p.field, &q.field [, size])
func (pstate *PackageState) eqmem(p *Node, q *Node, field *types.Sym, size int64) *Node {
	nx := pstate.nod(OADDR, pstate.nodSym(OXDOT, p, field), nil)
	ny := pstate.nod(OADDR, pstate.nodSym(OXDOT, q, field), nil)
	nx = pstate.typecheck(nx, Erv)
	ny = pstate.typecheck(ny, Erv)

	fn, needsize := pstate.eqmemfunc(size, nx.Type.Elem(pstate.types))
	call := pstate.nod(OCALL, fn, nil)
	call.List.Append(nx)
	call.List.Append(ny)
	if needsize {
		call.List.Append(pstate.nodintconst(size))
	}

	return call
}

func (pstate *PackageState) eqmemfunc(size int64, t *types.Type) (fn *Node, needsize bool) {
	switch size {
	default:
		fn = pstate.syslook("memequal")
		needsize = true
	case 1, 2, 4, 8, 16:
		buf := fmt.Sprintf("memequal%d", int(size)*8)
		fn = pstate.syslook(buf)
	}

	fn = pstate.substArgTypes(fn, t, t)
	return fn, needsize
}

// memrun finds runs of struct fields for which memory-only algs are appropriate.
// t is the parent struct type, and start is the field index at which to start the run.
// size is the length in bytes of the memory included in the run.
// next is the index just after the end of the memory run.
func (pstate *PackageState) memrun(t *types.Type, start int) (size int64, next int) {
	next = start
	for {
		next++
		if next == t.NumFields(pstate.types) {
			break
		}
		// Stop run after a padded field.
		if pstate.ispaddedfield(t, next-1) {
			break
		}
		// Also, stop before a blank or non-memory field.
		if f := t.Field(pstate.types, next); f.Sym.IsBlank() || !pstate.IsRegularMemory(f.Type) {
			break
		}
	}
	return t.Field(pstate.types, next-1).End() - t.Field(pstate.types, start).Offset, next
}

// ispaddedfield reports whether the i'th field of struct type t is followed
// by padding.
func (pstate *PackageState) ispaddedfield(t *types.Type, i int) bool {
	if !t.IsStruct() {
		pstate.Fatalf("ispaddedfield called non-struct %v", t)
	}
	end := t.Width
	if i+1 < t.NumFields(pstate.types) {
		end = t.Field(pstate.types, i+1).Offset
	}
	return t.Field(pstate.types, i).End() != end
}
